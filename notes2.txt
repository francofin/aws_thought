The Compute category offers services that allow computer systems to be provisioned to run applications, 
calculate complex calculations, and respond to requests.

The Storage category offers services that store data in the cloud.

The Database category includes relational and non-relational databases that can be used to store and query large amounts of data.
S3, which stands for Simple Storage Service,
Often referred to as an S3 bucket, this storage resource can handle many requests per second.
Another service, S3 Glacier, is designed for long-term storage.
We'll begin by creating an S3 bucket, which we'll use to store static assets.
The AWS-CLI lets you configure the access keys and communicate with the various web services directly from the command line.

On Windows, follow these steps to install AWS-CLI:

Download the AWS CLI MSI installer for Windows (64-bit).

Run the downloaded MSI installer and follow the on-screen instructions. By default, the AWS CLI installs to C:\Program Files\Amazon\AWSCLIV2.

To verify the installation, open the Start menu, search for cmd to open a command-prompt window, and at the command prompt use the aws --version command.

Configure AWS Credentials
Next we'll set up the AWS-CLI by running the following command:

Copy
aws-configure

Replace the preceding values with your own values for the AWS Access Key ID and the AWS Secret Access Key for your IAM user.

Notice that the value for the region name is us-east-2. This region points to area availability zones located in Ohio. 
Each region is a separate geographic area. Availability zones, however, are isolated locations within each region. 
Local zones enable you to place resources, such as compute and storage, in multiple locations closer to your end users. 
Although the us-east-2 region might not be the one closest to you, you'll use it throughout this course for consistency.

One of the major benefits of cloud computing is leveraging the vast infrastructure systems of a cloud provider. 
With the global reach of AWS, we can connect to users by orders of magnitude faster due to the number of data centers 
AWS uses throughout the world. There are six regions in the US currently, with more being built at a steady rate around the globe.

High performance and speed is relative to the distance that the request must travel from the data center. 
For example, when an S3 bucket is created, we must designate a region so that AWS knows which data center contains the S3 bucket.

In this step, we'll use the aws-sdk package to interface with AWS from the Node.js application. This package is a software development kit, or SDK.


Create a new folder called server in the root directory of the Deep Thoughts application.

In this folder, create a file named create-bucket.js.

In VS Code, open create-bucket.js and add the following expression at the top of the file:

Copy
// Load the AWS SDK for Node.js
const AWS = require('aws-sdk');

This package is responsible for the API that allows the application to communicate with the web service
mport the uuid package to create a unique S3 bucket name by adding the following code to create-bucket.js:

The preceding expression creates the s3 instance object with the designated API.

Next, create the bucketParams object that assigns the metadata of the bucket (such as the bucket name) by adding the following code:
Now we'll call the s3 instance object to create an S3 bucket using the bucketParamsâ€”by adding the following code:

npm install aws-sdk uuid
Now run the create-bucket.js file at the command line from the root directory of the Deep Thoughts application, as follows:
You should see a success message in the command line if you've successfully created a new S3 bucket.

Let's verify that the bucket was created by going to the S3 console from the AWS Management Console in the browser, where we should see something like the following image:
Congratulations, you've just connected to your first web service. With a successful connection, you confirmed that the aws-sdk could use the credentials that you configured, using the AWS-CLI to communicate with S3. This technique allows you to use the keys without exposing them in the code.

In this lesson, we'll learn how to use another web service from AWS that's available to use in the free tier, 
called DynamoDB. DynamoDB is a NoSQL database service that uses a 
key-value method to store data. We'll replace the MongoDB database in the Deep Thoughts application with DynamoDB.

DynamoDB has some special properties that makes it keenly suited for cloud computing on a large scale.
The overlying philosophy in AWS is to provide web services that can handle millions of requests every hour. 
DynamoDB, however, was made with high performance under extreme load conditions in mind.
If we use a large-scale-first mentality when designing web applications, we can circumvent the technical debt of database migration by starting with a system that can handle a high request load.

n the first step, we'll determine the access points of the data in the application. By access points, we mean which components
 will need access to the data, how variable the queries will be, and what type of data the components will need.

 DynamoDB is specialized for high performance at high request loads because of its ability to handle simple and repetitive queries.
 For database queries that are very complex and dynamic in nature, we might need to leverage different databases, 
 such as a relational database. AWS offers that in the form of RDS, or Relational Database Service.

 